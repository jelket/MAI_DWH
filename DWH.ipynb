{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78d7d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, row_number, coalesce, when, first, monotonically_increasing_id,current_timestamp\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DWH\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"/home/jovyan/postgresql-42.7.4.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/postgres\"\n",
    "properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"12345\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb320dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide = spark.read.jdbc(url=jdbc_url, table=\"source1.craft_market_wide\", properties=properties)\n",
    "masters_products = spark.read.jdbc(url=jdbc_url, table=\"source2.craft_market_masters_products\", properties=properties)\n",
    "orders_customers = spark.read.jdbc(url=jdbc_url, table=\"source2.craft_market_orders_customers\", properties=properties)\n",
    "df2 = orders_customers.join(masters_products, on=\"craftsman_id\", how=\"inner\") \n",
    "craftsmans = spark.read.jdbc(url=jdbc_url, table=\"source3.craft_market_craftsmans\", properties=properties)\n",
    "customers = spark.read.jdbc(url=jdbc_url, table=\"source3.craft_market_customers\", properties=properties)\n",
    "orders = spark.read.jdbc(url=jdbc_url, table=\"source3.craft_market_orders\", properties=properties)\n",
    "df3 = orders \\\n",
    "    .join(craftsmans, on=\"craftsman_id\", how=\"inner\") \\\n",
    "    .join(customers, on=\"customer_id\", how=\"inner\")\n",
    "\n",
    "columns = ['craftsman_name', 'craftsman_address', 'craftsman_birthday', 'craftsman_email',\n",
    "           'product_name', 'product_description', 'product_type', 'product_price',\n",
    "           'order_created_date', 'order_completion_date', 'order_status',\n",
    "           'customer_name', 'customer_address', 'customer_birthday', 'customer_email']\n",
    "df = [wide, df2, df3]\n",
    "df = [df.select([col(c) if c in df.columns else lit(None).alias(c) for c in columns]) for df in dfs]\n",
    "\n",
    "\n",
    "final_df = df[0].union(df[1]).union(df[2])\n",
    "\n",
    "window_craftsman = Window.orderBy(\"craftsman_name\", \"craftsman_birthday\")\n",
    "dwh_craftsmans = final_df.select(\"craftsman_name\", \"craftsman_address\", \"craftsman_birthday\", \"craftsman_email\") \\\n",
    "    .dropDuplicates([\"craftsman_name\", \"craftsman_birthday\"]) \\\n",
    "    .withColumn(\"craftsman_id\", row_number().over(window_craftsman))\n",
    "\n",
    "window_customer = Window.orderBy(\"customer_name\", \"customer_birthday\")\n",
    "dwh_customers = final_df.select(\"customer_name\", \"customer_address\", \"customer_birthday\", \"customer_email\") \\\n",
    "    .dropDuplicates([\"customer_name\", \"customer_birthday\"]) \\\n",
    "    .withColumn(\"customer_id\", row_number().over(window_customer))\n",
    "\n",
    "window_product = Window.orderBy(\"product_name\", \"product_price\")\n",
    "dwh_products = final_df.select(\"product_name\", \"product_description\", \"product_type\", \"product_price\") \\\n",
    "    .dropDuplicates([\"product_name\", \"product_price\"]) \\\n",
    "    .withColumn(\"product_id\", row_number().over(window_product))\n",
    "\n",
    "dwh_orders = final_df.join(d_products, [\"product_name\", \"product_price\"], \"left\") \\\n",
    "    .join(d_craftsmans, [\"craftsman_name\", \"craftsman_birthday\"], \"left\") \\\n",
    "    .join(d_customers, [\"customer_name\", \"customer_birthday\"], \"left\") \\\n",
    "    .select(\n",
    "        row_number().over(Window.orderBy(\"product_id\", \"craftsman_id\", \"customer_id\")).alias(\"order_id\"),\n",
    "        \"product_id\",\n",
    "        \"craftsman_id\",\n",
    "        \"customer_id\",\n",
    "        \"order_created_date\",\n",
    "        \"order_completion_date\",\n",
    "        \"order_status\"\n",
    "    )\n",
    "\n",
    "dwh_craftsmans = d_craftsmans.withColumn(\"load_dttm\", current_timestamp())\n",
    "dwh_customers = d_customers.withColumn(\"load_dttm\", current_timestamp())\n",
    "dwh_products = d_products.withColumn(\"load_dttm\", current_timestamp())\n",
    "dwh_orders = f_orders.withColumn(\"load_dttm\", current_timestamp())\n",
    "\n",
    "dwh_craftsmans.write.jdbc(url=jdbc_url, table=\"dwh.d_craftsmans\", mode=\"append\", properties=properties)\n",
    "dwh_customers.write.jdbc(url=jdbc_url, table=\"dwh.d_customers\", mode=\"append\", properties=properties)\n",
    "dwh_products.write.jdbc(url=jdbc_url, table=\"dwh.d_products\", mode=\"append\", properties=properties)\n",
    "dwh_orders.write.jdbc(url=jdbc_url, table=\"dwh.f_orders\", mode=\"append\", properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2291544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_load_date_df = spark.read.jdbc(url=jdbc_url, table=\"dwh.datamart\", properties=properties)\n",
    "\n",
    "last_load_date = last_load_date_df.agg(spark_max(\"load_dttm\")).collect()[0][0]\n",
    "if last_load_date is None:\n",
    "    filtered_customers_df = d_customers\n",
    "    filtered_products_df = d_products\n",
    "    filtered_craftsmans_df = d_craftsmans\n",
    "    filtered_orders_df = f_orders\n",
    "else:\n",
    "    filtered_customers_df = customers_df.filter(col(\"load_dttm\") > last_load_date)\n",
    "    filtered_products_df = products_df.filter(col(\"load_dttm\") > last_load_date)\n",
    "    filtered_craftsmans_df = craftsmans_df.filter(col(\"load_dttm\") > last_load_date)\n",
    "    filtered_orders_df = orders_df.filter(col(\"load_dttm\") > last_load_date)\n",
    "    \n",
    "joined_df = filtered_orders_df.join(filtered_products_df, \"product_id\") \\\n",
    "    .join(filtered_craftsmans_df, \"craftsman_id\") \\\n",
    "    .join(filtered_customers_df, \"customer_id\")\n",
    "\n",
    "joined_df = joined_df.withColumn(\"report_period\", F.date_format(col(\"order_created_date\"), \"yyyy-MM\"))\n",
    "\n",
    "window_spec = Window.partitionBy(\"craftsman_id\", \"report_period\").orderBy(\"order_completion_date\")\n",
    "joined_df = joined_df.withColumn(\"median_time_order_completed\",\n",
    "                                 datediff(col(\"order_completion_date\"), col(\"order_created_date\")))\n",
    "\n",
    "joined_df = joined_df.withColumn(\"customer_age\",\n",
    "                                 F.datediff(F.current_date(), col(\"customer_birthday\")) / 365.25)\n",
    "\n",
    "agg_df = joined_df.groupBy(\"craftsman_id\", \"craftsman_name\", \"craftsman_address\", \"craftsman_birthday\", \"craftsman_email\", \"report_period\") \\\n",
    "    .agg(\n",
    "        spark_sum(col(\"product_price\") * 0.9).alias(\"craftsman_money\"),\n",
    "        spark_sum(col(\"product_price\") * 0.1).alias(\"platform_money\"),\n",
    "        count(\"order_id\").alias(\"count_order\"),\n",
    "        avg(col(\"product_price\")).alias(\"avg_price_order\"),\n",
    "        avg(col(\"customer_age\")).alias(\"avg_age_customer\"),\n",
    "        expr(\"percentile_approx(median_time_order_completed, 0.5)\").alias(\"median_time_order_completed\"),\n",
    "        count(when(col(\"order_status\") == \"created\", True)).alias(\"count_order_created\"),\n",
    "        count(when(col(\"order_status\") == \"in progress\", True)).alias(\"count_order_in_progress\"),\n",
    "        count(when(col(\"order_status\") == \"delivery\", True)).alias(\"count_order_delivery\"),\n",
    "        count(when(col(\"order_status\") == \"done\", True)).alias(\"count_order_done\"),\n",
    "        count(when(col(\"order_status\").isin(\"created\", \"in progress\", \"delivery\"), True)).alias(\"count_order_not_done\")\n",
    "    )\n",
    "\n",
    "product_category_count_df = joined_df.groupBy(\"craftsman_id\", \"report_period\", \"product_type\") \\\n",
    "    .agg(count(\"product_id\").alias(\"product_count\"))\n",
    "\n",
    "window_spec_category = Window.partitionBy(\"craftsman_id\", \"report_period\").orderBy(col(\"product_count\").desc())\n",
    "top_product_category_df = product_category_count_df.withColumn(\"rank\", F.row_number().over(window_spec_category)) \\\n",
    "    .filter(col(\"rank\") == 1) \\\n",
    "    .select(\"craftsman_id\", \"report_period\", \"product_type\") \\\n",
    "    .withColumnRenamed(\"product_type\", \"top_product_category\")\n",
    "\n",
    "final_df = agg_df.join(top_product_category_df, [\"craftsman_id\", \"report_period\"], \"left\")\n",
    "final_df.write.jdbc(url=jdbc_url, table=\"dwh.datamart\", mode=\"append\", properties=properties)\n",
    "\n",
    "current_load_date = F.current_date()\n",
    "spark.read.jdbc(url=jdbc_url, table=\"dwh.datamart\", properties=properties) \\\n",
    "    .createOrReplaceTempView(\"datamart\")\n",
    "\n",
    "max_id_df = spark.sql(\"SELECT MAX(id) AS max_id FROM datamart\")\n",
    "max_id = max_id_df.collect()[0][0]\n",
    "\n",
    "next_id = 1 if max_id is None else max_id + 1\n",
    "\n",
    "spark.sql(f\"INSERT INTO datamart (id, load_dttm) VALUES ({next_id}, CURRENT_DATE)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
